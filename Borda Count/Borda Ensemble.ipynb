{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#GLASS DATASET IMPORT\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "columns=['id','RI','Na','Mg','Al','Si','K','Ca','Ba','Fe','Type']\n",
    "dataset = pd.read_csv('glass.csv',names=columns)\n",
    "dataset['Type'] = dataset['Type'].astype(int)\n",
    "labels = dataset['Type'].unique()\n",
    "yColumn = len(columns) -1\n",
    "trainColumns = range(yColumn)\n",
    "X = np.array(dataset.drop(['Type'], 1))\n",
    "y = np.array(dataset['Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset['Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#breast cancer dataset IMPORT\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "columns = ['code_num','thickness','uofcsize','uofcshape','adhesion','secsize','bnuclei','chromatinb','\\\n",
    "\t\t\tnnucleoi','mitoses','output']\n",
    "data = pd.read_csv('breast-cancer-wisconsin.data',names=columns)\n",
    "data['output'] = data['output'].astype(int)\n",
    "data.drop(['code_num'],1,inplace=True)\n",
    "data.replace('?',-99999, inplace=True)\n",
    "data = data.astype(int)\n",
    "X = np.array(data.drop(['output'], 1))\n",
    "y = np.array(data['output'])\n",
    "yColumn =9\n",
    "trainColumns = range(yColumn)\n",
    "data['output'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "df_majority = dataset[dataset.Type==2]\n",
    "df_minority1 = dataset[dataset.Type==1]\n",
    "df_minority7 = dataset[dataset.Type==7]\n",
    "df_minority3 = dataset[dataset.Type==3]\n",
    "df_minority5 = dataset[dataset.Type==5]\n",
    "df_minority6 = dataset[dataset.Type==6]\n",
    "\n",
    "\n",
    "df_minority_upsampled1 = resample(df_minority1, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=76,    # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    "df_minority_upsampled7 = resample(df_minority7, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=76,    # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    "df_minority_upsampled3 = resample(df_minority3, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=76,    # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    "df_minority_upsampled5 = resample(df_minority5, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=76,    # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    "df_minority_upsampled6 = resample(df_minority6, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=76,    # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    "# Combine majority class with upsampled minority class\n",
    "\n",
    "df_upsampled = pd.concat([df_majority, df_minority_upsampled1,df_minority_upsampled7,df_minority_upsampled3,df_minority_upsampled5,df_minority_upsampled6])\n",
    "print(df_upsampled.Type.value_counts())\n",
    "X = np.array(df_upsampled.drop(['Type'], 1))\n",
    "y = np.array(df_upsampled['Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "df_majority = data[data.output==2]\n",
    "df_minority = data[data.output==4]\n",
    "\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=458,    # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    " \n",
    "# Combine majority class with upsampled minority class\n",
    "df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
    "df_upsampled.output.value_counts()\n",
    "X = np.array(df_upsampled.drop(['output'], 1))\n",
    "y = np.array(df_['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#SONAR DATASET IMPORT\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "data = pd.read_csv('Sonar.csv')\n",
    "print(data.columns,data.Class.value_counts())\n",
    "yColumn = 60\n",
    "trainColumns = range(yColumn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "import numpy as np\n",
    "df_majority = data[data.Class==0]\n",
    "df_minority = data[data.Class==1]\n",
    "\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=111,    # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    " \n",
    "# Combine majority class with upsampled minority class\n",
    "df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
    "df_upsampled.Class.value_counts()\n",
    "X = np.array(df_upsampled.drop(['Class'], 1))\n",
    "y = np.array(df_upsampled['Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23    240\n",
       "19    240\n",
       "8     240\n",
       "12    240\n",
       "16    240\n",
       "20    240\n",
       "24    240\n",
       "1     240\n",
       "5     240\n",
       "9     240\n",
       "13    240\n",
       "17    240\n",
       "21    240\n",
       "25    240\n",
       "2     240\n",
       "10    240\n",
       "14    240\n",
       "18    240\n",
       "22    240\n",
       "26    240\n",
       "3     240\n",
       "7     240\n",
       "11    240\n",
       "15    240\n",
       "4     240\n",
       "6     238\n",
       "Name: 617, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load isolet data\n",
    "import pandas\n",
    "import numpy as np\n",
    "dTrain = pandas.io.parsers.read_csv('isolet1+2+3+4.data.gz',compression='gzip',header=None)\n",
    "yColumn = 617\n",
    "trainColumns = range(yColumn)\n",
    "dTrain[617] = dTrain[617].astype(int)\n",
    "dTrain[617].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "import numpy as np\n",
    "df_majority = dTrain[dTrain[617]!=6]\n",
    "df_minority = dTrain[dTrain[617]==6]\n",
    "\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=240,    # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    " \n",
    "# Combine majority class with upsampled minority class\n",
    "df_upsampled = pandas.concat([df_majority, df_minority_upsampled])\n",
    "X = np.array(df_upsampled.drop([617], 1))\n",
    "y = np.array(df_upsampled[617])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def k_fold_cross_validation(X, K, randomise = False):\n",
    "\t\"\"\"\n",
    "\tGenerates K (training, validation) pairs from the items in X.\n",
    "\n",
    "\tEach pair is a partition of X, where validation is an iterable\n",
    "\tof length len(X)/K. So each training iterable is of length (K-1)*len(X)/K.\n",
    "\n",
    "\tIf randomise is true, a copy of X is shuffled before partitioning,\n",
    "\totherwise its order is preserved in training and validation.\n",
    "\t\"\"\"\n",
    "\tif randomise: from random import shuffle; X=list(X); shuffle(X)\n",
    "\tfor k in list(range(K)):\n",
    "\t\ttraining = [x for i, x in enumerate(X) if i % K != k]\n",
    "\t\tvalidation = [x for i, x in enumerate(X) if i % K == k]\n",
    "\t\tyield training, validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(343, 618)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.945, random_state=42,stratify = y)\n",
    "X_train = np.column_stack([X_train,y_train])\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.85"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(1./26. * 100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.85"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "val = dict(Counter(y_test)).values()\n",
    "round(max(val)/sum(val)*100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing,neighbors,svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "\n",
    "clf1 = neighbors.KNeighborsClassifier()\n",
    "clf2 = svm.SVC(probability=True)\n",
    "clf3 = LogisticRegression()\n",
    "clf4 = tree.DecisionTreeClassifier()\n",
    "\n",
    "clf1.fit(X_train, y_train)\n",
    "clf2.fit(X_train, y_train)\n",
    "clf3.fit(X_train,y_train)\n",
    "clf4.fit(X_train,y_train)\n",
    "\n",
    "accuracy_1 = clf1.score(X_val, y_val)\n",
    "accuracy_2 = clf2.score(X_val, y_val)\n",
    "accuracy_3 = clf3.score(X_val,y_val)\n",
    "accuracy_4 = clf4.score(X_val,y_val)\n",
    "print(accuracy_1,accuracy_2,accuracy_3,accuracy_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test = y_test.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "def generate_preference(pred_proba,labels):\n",
    "    '''\n",
    "    Accepts: \n",
    "        pred_proba: Numpy array containing probabilities\n",
    "        labels: list containing output labels\n",
    "    Returns: Preference in form of list of list\n",
    "    '''\n",
    "    pred_proba = pred_proba[0]\n",
    "    num_class = pred_proba.shape[0]\n",
    "    vote_dic = {}\n",
    "    for i in range(num_class):\n",
    "        vote_dic[labels[i]] = pred_proba[i]\n",
    "    sorted_x = sorted(vote_dic.items(), key=operator.itemgetter(1))\n",
    "    sorted_x.reverse()\n",
    "    preference = []\n",
    "    for i in range(num_class):\n",
    "        preference.append(sorted_x[i][0])\n",
    "    return list(preference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def borda(preference_ballot):\n",
    "    '''\n",
    "    Accepts: list of list => preference_ballot\n",
    "    Returns: Winner\n",
    "    '''\n",
    "    counts = {}\n",
    "    candidates = list(set(preference_ballot[0]))\n",
    "    max_point = len(candidates)\n",
    "    for i in range(max_point):\n",
    "        counts[candidates[i]] = 0\n",
    "    for pref in preference_ballot:\n",
    "        for i in range(len(pref)):\n",
    "            counts[pref[i]] += (max_point -i)\n",
    "    return int(max(counts, key=counts.get))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_prediction_borda(test_example):\n",
    "    ensemble = [clf1,clf2,clf3]\n",
    "    labels = list(clf1.classes_)\n",
    "    preference_ballot = []\n",
    "    for base_learner in ensemble:\n",
    "        preference_ballot.append(generate_preference(base_learner.predict_proba(test_example),labels))\n",
    "    return borda(preference_ballot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def get_prediction_majority(test_example):\n",
    "    ensemble = [clf1,clf2,clf3]\n",
    "    predictions = []\n",
    "    for base_learner in ensemble:\n",
    "        predictions.append(base_learner.predict(test_example)[0])\n",
    "    occ = Counter(predictions)\n",
    "    return int(max(occ,key=occ.get))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "predictions_borda,predictions_majority = [],[]\n",
    "for test_example in X_val:\n",
    "    predictions_borda.append(get_prediction_borda(test_example))\n",
    "    predictions_majority.append(get_prediction_majority(test_example))\n",
    "print('Accuracy with Borda Count: ',accuracy_score(y_val,predictions_borda))\n",
    "print('Accuracy with Majority Voting',accuracy_score(y_val,predictions_majority))\n",
    "print('F-1 score of Borda Count',f1_score(y_val,predictions_borda,average='macro'))\n",
    "print('F-1 score of Majority Voting Classifier',f1_score(y_val,predictions_majority,average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$ 68.8 \\pm 3.68 $\n",
      "$ 48.72 \\pm 6.6 $\n",
      "$ 60.13 \\pm 8.35 $\n",
      "$ 67.97 \\pm 8.15 $\n",
      "$ 64.76 \\pm 7.15 $\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing,neighbors,svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import statistics\n",
    "acc_borda = []\n",
    "acc_majority = []\n",
    "acc_KNN = []\n",
    "acc_svc = []\n",
    "acc_dt = []\n",
    "for training, validation in k_fold_cross_validation(X_train, K=10):\n",
    "    training = np.array(training)\n",
    "    validation = np.array(validation)\n",
    "    X_train = [x for x in training[:,trainColumns]]\n",
    "    y_train = [y for y in training[:,yColumn]]\n",
    "    X_val = [x for x in validation[:,trainColumns]]\n",
    "    y_val = [y for y in validation[:,yColumn]]\n",
    "    \n",
    "    clf1 = neighbors.KNeighborsClassifier()\n",
    "    clf2 = svm.SVC(probability=True)\n",
    "    clf3 = tree.DecisionTreeClassifier()\n",
    "\n",
    "    clf1.fit(X_train, y_train)\n",
    "    clf2.fit(X_train, y_train)\n",
    "    clf3.fit(X_train,y_train)\n",
    "\n",
    "    acc_KNN.append(clf1.score(X_val, y_val))\n",
    "    acc_svc.append(clf2.score(X_val, y_val))\n",
    "    acc_dt.append(clf3.score(X_val,y_val))\n",
    "    \n",
    "    predictions_borda,predictions_majority = [],[]\n",
    "    for test_example in X_val:\n",
    "        predictions_borda.append(get_prediction_borda(test_example))\n",
    "        predictions_majority.append(get_prediction_majority(test_example))\n",
    "    acc_borda.append(accuracy_score(y_val,predictions_borda))\n",
    "    acc_majority.append(accuracy_score(y_val,predictions_majority))\n",
    "print('$',round(statistics.mean(acc_KNN)*100,2),'\\pm',round(statistics.stdev(acc_KNN)*100,2),'$')\n",
    "print('$',round(statistics.mean(acc_svc)*100,2),'\\pm',round(statistics.stdev(acc_svc)*100,2),'$')\n",
    "print('$',round(statistics.mean(acc_dt)*100,2),'\\pm',round(statistics.stdev(acc_dt)*100,2),'$')\n",
    "print('$',round(statistics.mean(acc_borda)*100,2),'\\pm',round(statistics.stdev(acc_borda)*100,2),'$')\n",
    "print('$',round(statistics.mean(acc_majority)*100,2),'\\pm',round(statistics.stdev(acc_majority)*100,2),'$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74.41\n",
      "78.67\n",
      "60.56\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing,neighbors,svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "clf1 = neighbors.KNeighborsClassifier()\n",
    "clf2 = svm.SVC(probability=True)\n",
    "clf3 = tree.DecisionTreeClassifier()\n",
    "\n",
    "y_train=X_train[:,-1]\n",
    "X_train=X_train[:,:-1]\n",
    "\n",
    "clf1.fit(X_train, y_train)\n",
    "clf2.fit(X_train, y_train)\n",
    "clf3.fit(X_train,y_train)\n",
    "\n",
    "print(round(clf1.score(X_test,y_test)*100,2))\n",
    "print(round(clf2.score(X_test,y_test)*100,2))\n",
    "print(round(clf3.score(X_test,y_test)*100,2))\n",
    "\n",
    "predictions_borda = []\n",
    "predictions_majority = []\n",
    "for test_example in X_test:\n",
    "        predictions_borda.append(get_prediction_borda(test_example))\n",
    "        predictions_majority.append(get_prediction_majority(test_example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68.68\n",
      "78.9\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(round(accuracy_score(y_test,predictions_borda)*100,2))\n",
    "print(round(accuracy_score(y_test,predictions_majority)*100,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing,neighbors,svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "clf1 = neighbors.KNeighborsClassifier()\n",
    "clf2 = svm.SVC(probability=True)\n",
    "clf3 = tree.DecisionTreeClassifier()\n",
    "\n",
    "y_train=X_train[:,-1]\n",
    "X_train=X_train[:,:-1]\n",
    "\n",
    "clf1.fit(X_train, y_train)\n",
    "clf2.fit(X_train, y_train)\n",
    "clf3.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Counter(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "probs = model.predict_proba(X_test)\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "# method I: plt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
