{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted Majority Game with Local Accuracy Estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A weighted voting game is a $n$ player game where there are $k$ available choices to vote and a weight is assigned to each voter. \n",
    "\n",
    "To maximize the performance of the ensemble, we need to give more weight to that member which has highest accuracy in the neighbourhood of the test point. \n",
    "\n",
    "In case of 2 class classification problem, if $X_{val}$ is the validation set, then the local weight of the classifiers is given by\n",
    "\n",
    "$$ w_i = log(\\frac{p_i}{1-p_i}) $$\n",
    "\n",
    "where p_i is the estimated probability of correct classification measured in the validation set.\n",
    "\n",
    "This requires the classifiers to be independent which can be assured by performing bootstrap aggregation or the classifier can simply be assumed as independent.\n",
    "\n",
    "In this notebook, we check the performance of this algorithm on a 2-class dataset. Since the dataset is simple, very few training examples are needed. We knowingly train the individual classifiers on very few points to show how ensembles perform well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "columns = ['code_num','thickness','uofcsize','uofcshape','adhesion','secsize','bnuclei','chromatinb','nnucleoi','mitoses','output']\n",
    "data = pd.read_csv('breast-cancer-wisconsin.data',names=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.drop(['code_num'],1,inplace=True)\n",
    "data.replace('?',-99999, inplace=True)\n",
    "data = data.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.array(data.drop(['output'], 1))\n",
    "y = np.array(data['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.655639097744 0.655639097744 0.681203007519 0.873684210526\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing,neighbors,svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.95,stratify=y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.80)\n",
    "\n",
    "clf1 = neighbors.KNeighborsClassifier()\n",
    "clf2 = svm.SVC()\n",
    "clf3 = LogisticRegression()\n",
    "clf4 = tree.DecisionTreeClassifier()\n",
    "\n",
    "clf1.fit(X_train, y_train)\n",
    "clf2.fit(X_train, y_train)\n",
    "clf3.fit(X_train,y_train)\n",
    "clf4.fit(X_train,y_train)\n",
    "\n",
    "accuracy1 = clf1.score(X_test, y_test)\n",
    "accuracy2 = clf2.score(X_test, y_test)\n",
    "accuracy3 = clf3.score(X_test,y_test)\n",
    "accuracy4 = clf4.score(X_test,y_test)\n",
    "\n",
    "print(accuracy1,accuracy2,accuracy3,accuracy4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_weights(p):\n",
    "    p[p==1.0] = 0.99 #avoid inf error\n",
    "    odds = (p)/(1-p)\n",
    "    return np.log(odds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "global_acc_vector=np.array([accuracy1,accuracy2,accuracy3])\n",
    "weights = get_weights(global_acc_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "         metric_params=None, n_jobs=1, n_neighbors=3, p=2, radius=1.0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "neigh = NearestNeighbors(n_neighbors=3)\n",
    "neigh.fit(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_local_weights(test_point,n_neigh):\n",
    "    nearest_indices = neigh.kneighbors(test_point,n_neighbors=n_neigh,return_distance=False)[0]\n",
    "    X_verify = X_val[nearest_indices]\n",
    "    y_verify = y_val[nearest_indices]\n",
    "    score_pred1 = clf1.score(X_verify,y_verify)\n",
    "    score_pred2 = clf2.score(X_verify,y_verify)\n",
    "    score_pred3 = clf3.score(X_verify,y_verify)\n",
    "    score_pred4 = clf4.score(X_verify,y_verify)\n",
    "    acc_vector = np.array([score_pred1,score_pred2,score_pred3,score_pred4])\n",
    "    weights=get_weights(acc_vector)\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_weighted_prediction(sample_point):\n",
    "    weights=get_local_weights(sample_point,4)\n",
    "    prediction=np.array([clf1.predict([sample_point]),clf2.predict([sample_point]),clf3.predict([sample_point]),clf2.predict([sample_point])])\n",
    "    quota_weight = 0.0\n",
    "    for _ in range(len(prediction)):\n",
    "        if prediction[_] == 4:\n",
    "            quota_weight = quota_weight + weights[_]\n",
    "    if quota_weight >= np.average(weights):\n",
    "        return 4\n",
    "    else:\n",
    "        return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "ensemble_pred=[]\n",
    "for _ in range(len(X_test)):\n",
    "    ensemble_pred.append(get_weighted_prediction(X_test[_]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.935338345865\n"
     ]
    }
   ],
   "source": [
    "ensemble_pred=np.array(ensemble_pred).reshape(y_test.shape)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test,ensemble_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def disagreement_measure(clf1,clf2,data):\n",
    "    output_clf1 = clf1.predict(data)\n",
    "    output_clf2 = clf2.predict(data)\n",
    "    return 1- accuracy_score(output_clf1,output_clf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def diversity_measure(ensemble_list,data,i):\n",
    "    ensemble_len = len(ensemble_list)\n",
    "    diversity = 0\n",
    "    for j in range(0,ensemble_len):\n",
    "        if j == i:\n",
    "            continue\n",
    "        diversity = diversity + disagreement_measure(ensemble_list[i],ensemble_list[j],data)\n",
    "    return float(diversity)/float(ensemble_len-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "diversity_values = []\n",
    "for i in range(0,4):\n",
    "    diversity_values.append(diversity_measure([clf1,clf2,clf3,clf4],X_val,i))\n",
    "weights = [0,0,0,0]\n",
    "for i in range(0,4):\n",
    "    for j in range(0,4):\n",
    "        if j == i:\n",
    "            continue\n",
    "        if diversity_values[i] >= diversity_values[j]:\n",
    "            weights[i] = weights[i] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 2, 3]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def banzhaf(weight, quota):\n",
    "\n",
    "    max_order = sum(weight)\n",
    "\n",
    "    polynomial = [1] + max_order*[0]               # create a list to hold the polynomial coefficients\n",
    "\n",
    "    current_order = 0                              # compute the polynomial coefficients\n",
    "    aux_polynomial = polynomial[:]\n",
    "    for i in range(len(weight)):\n",
    "        current_order = current_order + weight[i]\n",
    "        offset_polynomial = weight[i]*[0]+polynomial\n",
    "        for j in range(current_order+1):\n",
    "            aux_polynomial[j] = polynomial[j] + offset_polynomial[j]\n",
    "        polynomial = aux_polynomial[:]\n",
    "\n",
    "    banzhaf_power = len(weight)*[0]                                 # create a list to hold the Banzhaf Power for each voter\n",
    "    swings = quota*[0]                                              # create a list to compute the swings for each voter\n",
    "\n",
    "    for i in range(len(weight)):                                    # compute the Banzhaf Power\n",
    "        for j in range(quota):                                      # fill the swings list\n",
    "            if (j<weight[i]):\n",
    "                swings[j] = polynomial[j]\n",
    "            else:\n",
    "                swings[j] = polynomial[j] - swings[j-weight[i]]\n",
    "        for k in range(weight[i]):                                  # fill the Banzhaf Power vector\n",
    "            banzhaf_power[i] = banzhaf_power[i] + swings[quota-1-k]\n",
    "\n",
    "    # Normalize Index\n",
    "    total_power = float(sum(banzhaf_power))\n",
    "    banzhaf_index = map(lambda x: x / total_power, banzhaf_power)\n",
    "\n",
    "    return np.array(list(banzhaf_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.04166667  0.04166667 -0.20833333  0.125     ]\n",
      "[3, 0]\n"
     ]
    }
   ],
   "source": [
    "# weight threshold is [3,5]\n",
    "double_banzhaf = banzhaf(weights,4) - banzhaf(weights,6)\n",
    "print(double_banzhaf)\n",
    "pruned_ensemble = []\n",
    "pruned_weights = []\n",
    "\n",
    "while sum(pruned_weights) <= 3:\n",
    "    h = np.argmax(double_banzhaf)\n",
    "    if sum(pruned_weights) + weights[h] >6:\n",
    "            break\n",
    "    pruned_ensemble.append(h)\n",
    "    pruned_weights.append(weights[h])\n",
    "    double_banzhaf[h] = -144\n",
    "print(pruned_ensemble)     #ensemble of 1 2 and 3 is pruned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_weighted_prediction_ensemble(pruned_ensemble,sample_point):\n",
    "    clf = {0: clf1, 1: clf2, 2: clf3, 3: clf4}\n",
    "    weights=get_local_weights(sample_point,3)\n",
    "    prediction=np.array([clf[i].predict([sample_point]) for i in pruned_ensemble] )\n",
    "    quota_weight = 0.0\n",
    "    for _ in range(len(prediction)):\n",
    "        if prediction[_] == 4:\n",
    "            quota_weight = quota_weight + weights[_]\n",
    "    if quota_weight >= np.average(weights):\n",
    "        return 4\n",
    "    else:\n",
    "        return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95037593985\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "ensemble_pred=[]\n",
    "for _ in range(len(X_test)):\n",
    "    ensemble_pred.append(get_weighted_prediction_ensemble(pruned_ensemble,X_test[_]))\n",
    "ensemble_pred=np.array(ensemble_pred).reshape(y_test.shape)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test,ensemble_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
